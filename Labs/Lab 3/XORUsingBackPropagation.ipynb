{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training XOR Function Using Back-Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial hidden weights:\n",
      "[[0.50849646 0.45653358]\n",
      " [0.74856586 0.0362469 ]]\n",
      "Initial hidden biases:\n",
      "[[0.49645444 0.69028227]]\n",
      "\n",
      "Initial output weights:\n",
      "[[0.68368952]\n",
      " [0.42595845]]\n",
      "Initial output bias:\n",
      "[[0.09997033]]\n",
      "\n",
      "Final hidden weights:\n",
      "[[7.83208159 0.93013515]\n",
      " [7.8252924  0.93012415]]\n",
      "Final hidden biases:\n",
      "[[-0.0007043  -0.00207886]]\n",
      "\n",
      "Final output weights:\n",
      "[[ 26.27503554]\n",
      " [-33.00677212]]\n",
      "Final output bias:\n",
      "[[-0.00798849]]\n",
      "\n",
      "Output after 100000 epoch:\n",
      "[[0.03352632]\n",
      " [0.93094489]\n",
      " [0.93094471]\n",
      " [0.09223843]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoidDerivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Input dataset\n",
    "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "t = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "epoch = 100000\n",
    "lr = 0.1\n",
    "ILNeurons, HLNeurons, OLNeurons = 2, 2, 1\n",
    "\n",
    "# Random weights and bias initialization\n",
    "wh = np.random.uniform(size = (ILNeurons, HLNeurons))\n",
    "bh = np.random.uniform(size = (1, HLNeurons))\n",
    "wo = np.random.uniform(size = (HLNeurons, OLNeurons))\n",
    "bo = np.random.uniform(size = (1, OLNeurons))\n",
    "\n",
    "print(f\"Initial hidden weights:\")\n",
    "print(wh)\n",
    "print(f\"Initial hidden biases:\")\n",
    "print(bh)\n",
    "print(f\"\\nInitial output weights:\")\n",
    "print(wo)\n",
    "print(f\"Initial output bias:\")\n",
    "print(bo)\n",
    "\n",
    "# Training Algorithm\n",
    "for i in range(epoch):\n",
    "#     Forward Propagation\n",
    "    vh = np.dot(x, wh)\n",
    "    vh += bh\n",
    "    yh = sigmoid(vh)\n",
    "    \n",
    "    vo = np.dot(yh, wo)\n",
    "    vo += bo\n",
    "    yo = sigmoid(vo)\n",
    "    \n",
    "#     Back-Propagation\n",
    "    error = t - yo\n",
    "    deltao = error * sigmoidDerivative(yo)\n",
    "\n",
    "    hidden_error = deltao.dot(wo.T)\n",
    "    deltah = hidden_error * sigmoidDerivative(yh)\n",
    "    \n",
    "#     weight update\n",
    "    wo += yh.T.dot(deltao) * lr\n",
    "    bo += np.sum(deltao, axis=0, keepdims=True) * lr\n",
    "    wh += x.T.dot(deltah) * lr\n",
    "    bh = np.sum(deltah, axis=0, keepdims=True) * lr\n",
    "    \n",
    "print(f\"\\nFinal hidden weights:\\n{wh}\")\n",
    "print(f\"Final hidden biases:\\n{bh}\")\n",
    "print(f\"\\nFinal output weights:\\n{wo}\")\n",
    "print(f\"Final output bias:\\n{bo}\")\n",
    "print(f\"\\nOutput after {epoch} epoch:\\n{yo}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of Majority Function Using BackPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial hidden layer 1 weights:\n",
      "[[0.48415914 0.99807726]\n",
      " [0.39245753 0.17792472]\n",
      " [0.29932184 0.68691752]]\n",
      "initial hidden layer 1 biases:\n",
      "[[0.98990028 0.8421257 ]]\n",
      "\n",
      "Initial hidden layer 2 weights:\n",
      "[[0.40068737 0.8025034 ]\n",
      " [0.87894221 0.81344195]]\n",
      "Initial hidden layer 2 biases:\n",
      "[[0.75512805 0.08328155]]\n",
      "\n",
      "Initial output layer weights:\n",
      "[[0.10052292]\n",
      " [0.57858834]]\n",
      "Initial output layer bias:\n",
      "[[0.46549465]]\n",
      "\n",
      "Final hidden layer 1 weights:\n",
      "[[ 2.20578715  6.2322205 ]\n",
      " [ 4.64169896 -4.33373   ]\n",
      " [ 2.20578708  6.23221718]]\n",
      "Final hidden layer 1 biases:\n",
      "[[-0.01427052  0.01160984]]\n",
      "\n",
      "Final hidden layer 2 weights:\n",
      "[[ -4.13955628  15.13749799]\n",
      " [  5.85240207 -13.28330684]]\n",
      "Final hidden layer 2 biases:\n",
      "[[0.75512805 0.08328155]]\n",
      "\n",
      "Final output weights:\n",
      "[[11.96647674]\n",
      " [27.38240986]]\n",
      "Final output bias:\n",
      "[[-31.92428314]]\n",
      "\n",
      "Output after 100000 epoch:\n",
      "[[0.08873681]\n",
      " [0.01923363]\n",
      " [0.01625852]\n",
      " [0.99260297]\n",
      " [0.01923363]\n",
      " [0.923441  ]\n",
      " [0.99260297]\n",
      " [0.95463725]]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoidDerivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Input dataset\n",
    "x = np.array([[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1], [1, 0, 0], [1, 0, 1], [1, 1, 0], [1, 1, 1]])\n",
    "t = np.array([[0], [0], [0], [1], [0], [1], [1], [1]])\n",
    "\n",
    "epoch = 100000\n",
    "lr = 0.1\n",
    "ILNeurons, HL1Neurons, HL2Neurons, OLNeurons = 3, 2, 2, 1\n",
    "\n",
    "# Random weights and bias initialization\n",
    "wh1 = np.random.uniform(size = (ILNeurons, HL1Neurons))\n",
    "bh1 = np.random.uniform(size = (1, HL1Neurons))\n",
    "wh2 = np.random.uniform(size = (HL1Neurons, HL2Neurons))\n",
    "bh2 = np.random.uniform(size = (1, HL2Neurons))\n",
    "wo = np.random.uniform(size = (HL2Neurons, OLNeurons))\n",
    "bo = np.random.uniform(size = (1, OLNeurons))\n",
    "\n",
    "print(f\"Initial hidden layer 1 weights:\\n{wh1}\")\n",
    "print(f\"initial hidden layer 1 biases:\\n{bh1}\")\n",
    "print(f\"\\nInitial hidden layer 2 weights:\\n{wh2}\")\n",
    "print(f\"Initial hidden layer 2 biases:\\n{bh2}\")\n",
    "print(f\"\\nInitial output layer weights:\\n{wo}\")\n",
    "print(f\"Initial output layer bias:\\n{bo}\")\n",
    "\n",
    "\n",
    "# Training Algorithm\n",
    "for i in range(epoch):\n",
    "#     Forward Propagation\n",
    "    vh1 = np.dot(x, wh1)\n",
    "    vh1 += bh1\n",
    "    yh1 = sigmoid(vh1)\n",
    "    \n",
    "    vh2 = np.dot(yh1, wh2)\n",
    "    vh2 += bh2\n",
    "    yh2 = sigmoid(vh2)\n",
    "    \n",
    "    vo = np.dot(yh2, wo)\n",
    "    vo += bo\n",
    "    yo = sigmoid(vo)\n",
    "    \n",
    "#     Back-Propagation\n",
    "    error = t - yo\n",
    "    deltao = error * sigmoidDerivative(yo)\n",
    "\n",
    "    hidden2_error = deltao.dot(wo.T)\n",
    "    deltah2 = hidden2_error * sigmoidDerivative(yh2)\n",
    "    \n",
    "    hidden1_error = deltah2.dot(wh2.T)\n",
    "    deltah1 = hidden1_error * sigmoidDerivative(yh1)\n",
    "    \n",
    "#     weight update\n",
    "    wo += yh2.T.dot(deltao) * lr\n",
    "    bo += np.sum(deltao, axis=0, keepdims=True) * lr\n",
    "    \n",
    "    wh2 += yh1.T.dot(deltah2) * lr\n",
    "    bh = np.sum(deltah2, axis=0, keepdims=True) * lr\n",
    "    \n",
    "    wh1 += x.T.dot(deltah1) * lr\n",
    "    bh1 = np.sum(deltah1, axis=0, keepdims=True) * lr\n",
    "    \n",
    "print(f\"\\nFinal hidden layer 1 weights:\\n{wh1}\")\n",
    "print(f\"Final hidden layer 1 biases:\\n{bh1}\")\n",
    "print(f\"\\nFinal hidden layer 2 weights:\\n{wh2}\")\n",
    "print(f\"Final hidden layer 2 biases:\\n{bh2}\")\n",
    "print(f\"\\nFinal output weights:\\n{wo}\")\n",
    "print(f\"Final output bias:\\n{bo}\")\n",
    "print(f\"\\nOutput after {epoch} epoch:\\n{yo}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
